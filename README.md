# Awesome Algorithmic Fairness [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

> A curated list of awesome algorithmic fairness resources.

## Introduction

- [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
- [Tutorial: 21 fairness definitions and their politics](https://youtu.be/jIXIuYdnyyk)
- [NIPS 2017 Fairness In Machine Leaning](https://nips.cc/Conferences/2017/Schedule?showEvent=8734). ([Video](https://vimeo.com/248490141)), ([Slides](http://fairml.how/tutorial/#/))
- [A Tutorial on Fairness in Machine Learning](https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb)

## Tutorials and examples

- [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
- [Attacking discrimination with smarter machine learning](http://research.google.com/bigpicture/attacking-discrimination-in-ml/)
- [Tutorial: 21 fairness definitions and their politics](https://youtu.be/jIXIuYdnyyk)

## Guideline, Principle and Practices
 * [Google AI - Responsible AI Practices](https://ai.google/education/responsible-ai-practices)

## Selection of research papers

## Software packages

### Python

* [Fairness comparison](https://github.com/algofairness/fairness-comparison)
* [AIF360](https://github.com/ibm/aif360)
* [BlackBoxAuditing](https://github.com/algofairness/BlackBoxAuditing)
* [Themis ML](https://github.com/cosmicBboy/themis-ml)
* [FairML](https://github.com/adebayoj/fairml)
* [Themis](https://github.com/LASER-UMASS/Themis)
* [FairSquare](https://github.com/sedrews/fairsquare)
* [FairTest](https://github.com/columbia/fairtest)
* [Aequitas](https://github.com/sakshiudeshi/Aequitas)
* [Aequitas](https://dsapp.uchicago.edu/projects/aequitas/)
* [What If Tool](https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/interactive_inference)

### R

(To be added.)

## Datasets

* [Data and analysis for 'Machine Bias'](https://github.com/propublica/compas-analysis)

## Organizations, workgroups and conferences

### Corporation research programs

* IBM [Trusted AI](https://www.research.ibm.com/artificial-intelligence/trusted-ai/)
* Google Brain [Pair (People + AI Research)](https://ai.google/research/teams/brain/pair)

### Academic research centers

* The University of Chicago [Center of Data Science and Public Policy](https://dsapp.uchicago.edu)
* UC Berkeley [Center for Technology, Society & Policy](https://ctsp.berkeley.edu/) [Algorithmic Fairness and Opacity Worknig Group](http://afog.berkeley.edu/)
* Harvard [Algorithmic Fairness](http://fairness.haverford.edu/)
* MIT [Active Fairness in Algorithmc Decision Making](https://www.media.mit.edu/projects/active-fairness/)
* [AI Now Institute](https://ainowinstitute.org/)

### Activist groups

* [AlgorithmWatch](AlgorithmWatch)

### Conferences

* [ACM FAT*](https://fatconference.org/)
* [AI Now Symposium](https://symposium.ainowinstitute.org/)
* [FAT/ML](http://www.fatml.org/)
* [FairWare](http://fairware.cs.umass.edu/index.html)

## Contribute

Contributions welcome! Read the [contribution guidelines](contributing.md) first.

## License

[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](http://creativecommons.org/publicdomain/zero/1.0)

To the extent possible under law, Pomin Wu has waived all copyright and
related or neighboring rights to this work.
